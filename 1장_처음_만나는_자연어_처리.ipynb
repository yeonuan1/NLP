{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "2024.08.08 / 1일차 학습 목표\n",
        "- 딥러닝 기반 자연어 처리 모델, 트랜스퍼 러닝 개념 이해하기\n",
        "- 학습 파이프라인 및 개발 환경 숙지하기"
      ],
      "metadata": {
        "id": "HyOfxiugkH40"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1-1. 딥러닝 기반 자연어 처리 모델\n",
        "\n",
        "## 기계의 자연어 처리\n",
        "- 자연어 처리 모델은 자연어를 입력으로 받아 해당 입력이 특정 범주일 확률을 반환하는 확률함수임.\n",
        "- 딥러닝 기반 자연어 처리 모델은 출력된 확률을 후처리 하여 자연어 형태로 가공해 반환함 (문서 분류, 문장 쌍 분류, 개체명 인식, 질의응답, 문장 생성)\n",
        "\n",
        "## 딥러닝 모델의 학습\n",
        "- 학습이란 모델의 출력이 정답에 가까워지도록 모델을 업데이트하는 과정을 말함."
      ],
      "metadata": {
        "id": "OakmZQbkkVeU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1-2. 트랜스퍼 러닝\n",
        "\n",
        "## 트랜스퍼 러닝\n",
        "- 특정 태스크를 학습한 모델을 다른 태스크의 수행에 재사용하는 기법.\n",
        "- 태스크를 처음부터 학습하는 것이 아니라 지식 전이를 이용하여 보다 빠르게 학습하고 수행 능력이 향상됨\n",
        "- 업스트림 태스크를 학습하는 과정이 pretrain이고 다음 올 단어 맞히기나 빈칸 채우기 등 대규모 말뭉치의 문맥을 이해하는 과제이며 그 다음으로 수행되는 다운스트림 태스크는 문서 분류, 개체명 인식 등 자연어 처리의 구체적인 문제들임.\n",
        "\n",
        "## 업스트림 태스크\n",
        "- pretrain을 통해 자연어의 풍부한 문맥을 모델에 내재화하는 것으로, 이를 다양한 다운스트림 태스크에 적용해 성능을 올릴 수 있음.\n",
        "- GPT 계열 모델은 다음 단어 맞히기 태스크로 pretrain하고 다음 단어 맞히기로 업스트림 태스크를 수행한 모델을 언어 모델이라 함.\n",
        "- BERT 계열 모델은 빈칸 채우기 태스크로 pretrain하며, 빈칸 채우기로 업스트림 태스크를 수행한 모델을 마스트 언어 모델이라 함.\n",
        "- 업스트림 태스크는 사람이 일일이 정답을 만들어야 하는 지도학습과 달리 텍스트만 있으면 다량의 학습 데이터를 생성하여 데이터 내에서 정답을 만들고 이를 바탕으로 학습할 수 있음. 이를 자기지도 학습(self-supervied learning)이라 함.\n",
        "\n",
        "## 다운스트림 태스크\n",
        "- 다운스트림 태스크는 자연어 처리의 구체적인 과제들로, 업스트림 태스크로 pretrain한 근본적인 이유임.\n",
        "- 보통 학습을 마친 업스트림 태스크 모델을 그대로 사용하거나 태스크 모듈을 덧붙인 형태로 사용하며, 문장 생성을 제외한 대부분의 과제는 마스크 언어 모델(BERT계열)을 사용함.\n",
        "- 이 책에서 소개하는 다운스트림 태스크의 본질은 분류로 자연어 입력이 해당하는 범주를 확률로 반환하며, 학습 방식은 파인 튜닝임.\n",
        "- 파인 튜닝은 pretrain을 마친 BERT 모델을 다운스트림 태스크에 맞게 업데이트하는 방식임.\n",
        "\n",
        "## 문서 분류\n",
        "- 자연어를 입력받아 입력이 어떤 범주에 속하는지 확률값을 반환함.\n",
        "\n",
        "## 자연어 추론\n",
        "- 문장 2개를 입력 받아 두 문장 사이의 관계가 참/거짓/중립 중 어떤 범주인지 확률값을 반환함.\n",
        "\n",
        "## 개체명 인식\n",
        "- 자연어를 입력 받아 기관명/인명/지명 등 어떤 개체명 범주에 속하는지 확률값을 반환함.\n",
        "\n",
        "## 질의응답\n",
        "- 자연어(질문+지문)를 입력 받아 각 단어가 정답의 시작일 확률값과 끝일 확률값을 반환함.\n",
        "\n",
        "## 문장 생성\n",
        "- GPT 계열 언어 모델이 널리 쓰이며, 자연어(문장)를 입력 받아 어휘 전체에 대한 확률값을 반환함.\n",
        "- 이 확률값은 입력된 문장 다음에 올 단어로 얼마나 적절한지를 나타내는 점수임.\n",
        "\n",
        "\n",
        "다운스트림 태스크를 학습하는 방식은 파인튜닝 외에도 프롬프트 튜닝, 인컨텍스트 러닝 등이 있음."
      ],
      "metadata": {
        "id": "9WKkhP3nyEOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1-3. 학습 파이프라인 소개\n",
        "\n",
        "- 모델 학습 전체의 파이프라인은 다음과 같음.\n",
        "1. 각종 설정값 정하기\n",
        "2. 데이터 내려받기\n",
        "3. pretrain을 마친 모델 준비하기\n",
        "4. 토크나이저 준비하기\n",
        "5. 데이터 로더 준비하기\n",
        "6. 태스크 정의하기\n",
        "7. 모델 학습하기\n",
        "\n",
        "## 각종 설정값 정하기\n",
        "- 어떤 pretrain 모델을 사용할지, 학습에 사용할 데이터는 무엇인지, 학습 결과는 어디에 저장할지 등에 해당하며, 설정값들은 미리 선언해둠.\n",
        "- 하이퍼파라미터는 모델 구조와 학습에 직접 관계된 설정값으로 learning rate, batch size 등이 있고 역시 매우 중요함.\n",
        "\n",
        "## 데이터 내려받기\n",
        "- pretrain된 모델을 다운스트림 데이터로 파인튜닝하기 위해서는 다운스트림 데이터를 미리 다운받아 둬야 함.\n",
        "\n",
        "## 프리트레인을 마친 모델 준비하기\n",
        "- 대규모 말뭉치를 활용한 프리트레인에는 많은 리소스가 필요함.\n",
        "- 허깅페이스에서 만든 오픈소스 파이썬 패키지인 transformers를 이용하면 BERT, GPT 같은 모델을 사용할 수 있음.\n",
        "- 허깅페이스 모델 허브에 등록된 kcbert-base 모델을 사용할 수 있도록 준비함.\n",
        "\n",
        "## 토크나이저 준비하기\n",
        "- 자연어 처리 모델의 입력은 대개 문장보다 작은 단위인 토큰으로, 분리 기준은 띄어쓰기나 형태소 등이 있음.\n",
        "- 문장을 token sequence로 분석하는 과정을 토큰화, 토큰화를 수행하는 프로그램이 토크나이저로 이 책에서는 BPE나 워드피스 알고리즘을 채택한 토크나이저를 활용함.\n",
        "\n",
        "## 데이터 로더 준비하기\n",
        "- 파이토치는 딥러닝 모델 학습을 지원하는 파이썬 라이브러리로 데이터 로더가 포함되어 있음.\n",
        "- 데이터 로더는 데이터를 batch 단위로 모델에 밀어 넣어주며 전체 데이터 중 일부 인스턴스를 샘플링하여 배치를 구성함.\n",
        "- 데이터셋은 로더의 구성요소 중 하나로 문서+레이블로 구성된 여러 인스턴스를 보유함.\n",
        "- 데이터 로더가 배치를 만들 때 인스턴스를 뽑는 방식을 사용자가 지정할 수 있음.\n",
        "- 동일한 배치 내에 있는 문장들의 토큰 개수가 같아야 할 때가 많은데, 이때는 가장 긴 토큰 개수에 맞춰 짧은 인스턴스의 길이를 늘여서 맞춰줌.\n",
        "- 이렇게 배치의 모양 등을 정비해 모델의 최종 입력으로 만드는 과정을 collate라 하며, 컬레이트에는 파이썬 list를 파이토치 tensor로 변환하는 등의 자료형 변환도 포함됨.\n",
        "- 인덱싱은 각 토큰을 그에 해당하는 정수로 변환하는 것으로, 보통 토크나이저가 토큰화와 함께 수행함.\n",
        "\n",
        "## 태스크 정의하기\n",
        "- 이 책에서 학습에 사용하는 파이토치 라이트닝 라이브러리는 딥러닝 모델 학습 시 반복적인 내용을 대신 수행해줘 사용자가 모델 구축에만 신경쓸 수 있게 도움.\n",
        "- pytorch lightning이 제공하는 lightning 모듈을 상속받아 태스크를 정의하는데 이는 모델과 최적화 방법, 학습과정 등을 포함함.\n",
        "- 태스크의 최적화 방법으로는 모델의 출력과 정답 사이의 차이를 최소화하기 위해 optimizer, learn rate scheduler 등을 정의해둠.\n",
        "- 모델 학습은 batch 단위로 이루어져 모델에 배치를 입력한 뒤 출력과 정답의 차이를 계산해 이를 최소화하는 방향으로 모델을 업데이트하는 순환 과정을 거치고 이를 step이라 함.\n",
        "- 태스크의 학습 과정은 이러한 1회 step에서 벌어지는 일들을 정의해둠.\n",
        "\n",
        "## 모델 학습하기\n",
        "- trainer는 파이토치 라이트닝에서 제공하는 객체로 실제 학습을 수행하며, GPU 등 하드웨어 설정, 학습 기록 로깅, 체크포인트 저장 등 복잡한 설정을 알아서 해줌."
      ],
      "metadata": {
        "id": "xLAZhSEY4sx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1-4. 개발 환경 설정\n",
        "- 코랩\n",
        "- 구글 드라이브와 연결\n",
        "    - from google.colab import drive\n",
        "    - drive.mount('/gdrive', force_remount=True)\n",
        "- 코랩 노트북 복사"
      ],
      "metadata": {
        "id": "spNNoCIHCar3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jC6meKDWkEtN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AKIipqFwkfH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hsLP8R7skMCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WRVW8N_NkfqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "17yXoZsAkhwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T0OPnqT2kjA1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}